% arara: pdflatex
\documentclass[10pt,a4paper]{article}
\def\gettexliveversion#1(#2 #3 #4#5#6#7#8)#9\relax{#4#5#6#7}
\edef\texliveversion{\expandafter\gettexliveversion\pdftexbanner\relax}

\ifnum\texliveversion<2018
\usepackage[utf8]{inputenc}
\else
\fi
\usepackage[T1]{fontenc}

\usepackage[spanish,es-sloppy]{babel}
\spanishdatedel

\usepackage{amsmath,amsthm}
\usepackage[cmintegrals]{newtxmath}
\usepackage{xcolor}

\theoremstyle{definition}
\newtheorem{definition}{Definición}[section]
\newtheorem{proposition}{Proposición}[section]
\newtheorem{corollary}{Corolario}[section]
\newtheorem{example}{Ejemplo}[section]
\begin{document}
%\pagecolor{black}
%\color{white}
\section{Formas Canónicas}

\subsection{Valores y Vectores Propios}

En lo que sigue de este capitulo, $U$, $V$, $W$ denotarán $\mathbb{K}$-espacios vectoriales de dimensión finita y $\mathbb{K}$ denotará los cuerpos $\mathbb{R}$ o $\mathbb{C}$, salvo mención especifica distinta.

\begin{definition}
Dada una transformación lineal $T\colon V \rightarrow{V}$, un número $\lambda\in\mathbb{K}$ se llama \emph{valor propio} o \emph{autovalor} de $T$, si existe un vector $v\in V$, $v\neq0$, tal que $T(v)=\lambda v$. Este vector se llama \emph{vector propio} o \emph{autovector} de $T$ correspondiente al autovalor $\lambda$.

Llamaremos valor propio y vector propio de una matriz $A$, al valor propio y vector propio correspondiente de la transformación lineal $L_{A}$, respectivamente.
\end{definition}

Los autovectores de $T$ y $A_{T}$, en general, se hallan en espacios vectoriales distintos y no tienen que ser iguales. En cambio los autovalores que se hallan en el mismo cuerpo $\mathbb{K}$, por lo que cabe la pregunta: ¿son estos iguales o distintos? Una elegante respuesta a esta interrogante se da en las siguientes proposiciones.

Sea $\{v_1,\ldots,v_n\}$ una base de $V$ y $A_{T}$ la matriz asociada a la transformación lineal $T\colon V \rightarrow{V}$ en esta base. A cada vector $v\in V$ , $v = \sum\limits_{j=1}^{n}x_{j}v_{j},$ le asociamos su vector de coordenadas $x_v=(x_1,\ldots,x_n)\in\mathbb{K}$. Con estas notaciones tenemos el siguiente resultado.

\begin{proposition}
La función $\psi\colon V\rightarrow\mathbb{K}^{n\times 1}$, definida por $\psi(v)= x_v$, es un isomorfismo y satisface \[ \psi(T(v))=A_{T}(x_v) \].    
\end{proposition}

\begin{proof}
Es inmediato que $\psi$ es una transformación lineal, además es un isomorfismo, pues lleva la base $v_{i}$ de $V$ en la base canónica $e_{j}$ de $\mathbb{K}^{n \times n}$.

Por otro lado

\begin{flalign*}
\psi(T(v_{j}))  &=\psi(\sum\limits_{i=1}^{n}a_{ij}v_{i}) = (a_{1j},a_{2j},\ldots,a_{nj}) = A_{T}(e_{j})
\intertext{de donde}
\psi(T(v_{j}))  &=\psi(\sum\limits_{j=1}^{n}x_{j}T(v_{j})) = \sum\limits_{j=1}^{n}x_{j}\psi(T(v_{j}))\\
\psi(T(v_{j}))  &=\sum\limits_{x_{j}}^{n}{A_{T}}(e_{j}) = A_{T}(x_{1},\ldots,x_{n})^{t}\\
\psi(T(v_{j}))  &=A_{T}(x_{v})
\end{flalign*}
Esto concluye la prueba de la proposición.
\end{proof}

\begin{proposition}
Una transformación lineal $T\colon V\rightarrow V$ y su matriz asociada $A_{T}$ tienen los mismos autovalores.
\end{proposition}

\begin{proof}
Sea $\lambda$ un autovalor de $T$ y $v\in V$ un autovector correspondiente a $\lambda$, entonces
\begin{flalign*}
A_{T}(x_{v}) &= \psi(T_{v})\\
A_{T}(x_{v}) &= \psi(\lambda v)=\lambda\psi(v)\\
A_{T}(x_{v}) &= \lambda x_{v}
\end{flalign*}
Esto prueba que $\lambda$ es un autovalor de $A_{T}.$

Recíprocamente, sea $\lambda$ un autovalor de $A_{T}$ y $x\in\mathbb{K}^{n\times 1}$ un correspondiente autovector. Existe entonces un vector $v\in V$ tal que $\psi(v)=x$ (pues $\psi$ es un isomorfismo), de donde
%\[
%\begin{aligned}
%\psi(T_{v}) &\rightarrow\rn[1]\\
%(x,y,z)&\longmapsto\sign\left(\frac{2}{x^{2}+y^{2}+z^{2}+1}-1\right)-6.
%\end{aligned}
%\]
\begin{align*}
\psi(T_{v}) &= A_{T}x \\
            &= \lambda x = \lambda\psi(v)\\
            &= \psi(\lambda v)
\end{align*}
 
Siendo $\psi$ inyectiva, resulta $T(v)  = \lambda v$. Como $v \neq0$, $\lambda$ es un autovalor de $T$. Esto prueba la proposición.

\end{proof}

\begin{proposition}
    Una transformación lineal $T: V \rightarrow V$ y su matriz asociada $A_{T}$ tienen  los mismos autovalores.
\end{proposition}

\begin{proof}
	Sea $\lambda$ un autovalor de $T$ y $v \in V$ un autovector correspondiente a $\lambda$, entonces
	\begin{align*}
	A_{T}(x_{v})	& = \psi(T(v)) \qquad\qquad(\text{por la proposición})\\
	& = \psi(\lambda v) = \lambda \psi(v)\\
	& = \lambda x_{v}
	\end{align*}
	Esto prueba que $\lambda$ es un autovector de $A_{T}$. \\
	Recíprocamente, sea $\lambda$ un autovalor de $A_{T}$ y $x \in \mathbb{K}^{n \time 1}$ un correspondiente autovector. Existe entonces un vector $v \in V$ tal que $\psi(v) = x$(pues $\psi$ es un isomorfismo), de donde
	\begin{align*}
	\psi(T(v)) & =  \psi(T(v))\qquad\qquad(\text{por la proposición})\\
	& = \psi(\lambda v) = \lambda \psi(v)\\
	& = \lambda (x_{v})
	\end{align*}
	siendo $\psi$ inyectiva, resulta $T(v) = \lambda v$. Como $v \neq 0$, $\lambda$ es autovalor de $T$.
\end{proof}

\begin{corollary}
Si $A$, $P$ $\in \mathbb{K}^{n \times n}$ y $P$ es inversible, entonces $A$ y $P^{-1}AP$ tienen  los mismos autovalores.
\end{corollary}

\begin{proof}
Es suficiente observar que $A$ y $P^{-1}AP$ son matrices asociadas a una misma transformación lineal.
\end{proof}

\noindent La existencia de de autovalores de una transformación lineal depende del cuerpo $\mathbb{K}$ y de la dimensión del espacio vectorial, como se muestra en el siguiente ejemplo.

\begin{example}
La transformación lineal $T\colon\mathbb{R}^{2} \rightarrow \mathbb{R}^{2}$, $T(x,y)=(-y,x)$ no posee autovalores en $\mathbb{R}$.\\

En efecto, supongamos que $\lambda \in \mathbb{R} $ es un autovalor de $T$ y $v = (a,b) \neq 0$ un correspondiente autovector. Por definición \\

$$(-b,a) = T(a,b) = \lambda(a,b)$$. \\
ecuación que no posee solución en $\mathbb{R}.$
\end{example}

\section{Tiangulación de Matrices. El Teorema de Cayley-Hamilton}
Definición. Diremos que una matriz $A\in \mathbb{K}^{n \times n}$ es \textbf{triangulable}  si es semejante a una matriz triangular(superior). Una transformación lineal $T\colon V\rightarrow V$ es \textbf{triangulable} si existe una base de $V$ en la que la matriz asociada a $T$ es triangular.

Una proposición importante sobre la estructura de una matriz es la siguiente.
\begin{proposition}
Sea $\mathbb{K}=\mathbb{C}$. Toda transformación lineal $T\colon V\rightarrow V$ es triangulable.
\end{proposition}

\begin{proof}
Esta demostración se hará por inducción sobre $n=\dim V$. Si $n>1$, suponemos que la proposición es valida para todo espacio vectorial de dimensión $n-1$. Consideremos la transformación lineal $T^{\bigtriangledown}\colon V^{*} \rightarrow V^{*}$, definida por $T^{\bigtriangledown}(f)=f\circ T$, para $f\in V^{*}$.

Sea $\lambda\in\mathbb{C}$ un autovalor de $T^{\bigtriangledown}$ y $g\in V^{*}$ un correspondiente autovector, esto es \[T^{\triangledown} = \lambda g ,~ g\neq 0.\] El subespacio de $V$ \[S = \{v \in V / g(v) = 0\}\] tiene dimensión $n-1$ y es invariante por $T(T(s)\subset S)$. Por hipótesis inductiva, $S$ posee una base $\{v_{1},\ldots,v_{n}\}$en la que $T$ se escribe como

\begin{align*}
		T(v_{1}) & = \lambda_{1}v_{1}\\
		T(v_{2}) & = a_{12}v_{1} + \lambda_{2}v_{2}\\
		& \vdots\\
		T(v_{n-1}) & = a_{1,n-1}v_{1} +...+ \lambda_{n-1}v_{n-1}
\end{align*}
Si a los vectores $v_{1},\ldots,v_{n}$ agregamos un vector $v_{n}$ a fin de completar una base de $V$, con la expresión \[T(v_{n}) = a_{1n}v_{1},...,\lambda v_{n} \]
la matriz asociada a $T$, en la base $\{v_{1},\ldots,v_{n}\}$ es triangular superior.
\end{proof}
% https://www.sciencedirect.com/search/advanced?tak=Minimal%20polynomial&show=25&sortBy=relevance
% https://www.sciencedirect.com/science/article/pii/S1575181318302626
\end{document}